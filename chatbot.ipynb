{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import pickle\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, load_model\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, LSTM\n",
    "from keras.layers.merge import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('C:\\\\Users\\\\abhay\\\\Desktop\\\\QNA\\\\dataq.json','r') as f:\n",
    "    data = json.load(f)\n",
    "# with open('data.json','r') as f:\n",
    "#     data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for i in range(len(data)):\n",
    "    d[i] = dict(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "for key,value in d.items():\n",
    "    data_dict[d[key]['title']] = d[key]['rules']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(\"[^a-z]+\",\" \",sentence)  # taking only alphabets\n",
    "    sentence = sentence.split()\n",
    "    sentence = [i for i in sentence if len(i)>1]\n",
    "    sentence = \" \".join(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,caption_list in data_dict.items():\n",
    "    for i in range(len(caption_list)):\n",
    "        caption_list[i] = clean_text(caption_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "for key in data_dict.keys():\n",
    "    [vocab.update(sentence.split()) for sentence in data_dict[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = []\n",
    "for key in data_dict.keys():\n",
    "    [total_words.append(i) for d in data_dict[key] for i in d.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "count = collections.Counter(total_words)\n",
    "freq_count = dict(count)\n",
    "# print(freq_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_freq = sorted(freq_count.items(),reverse=True,key=lambda x:x[1])\n",
    "total_words = [i[0] for i in sorted_freq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = {}\n",
    "for i,word in enumerate(total_words):\n",
    "    word_to_index[word] = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word_to_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_map = {}\n",
    "title_map_idx = {}\n",
    "for i,key in enumerate(data_dict.keys()):\n",
    "    title_map[key] = i+1\n",
    "    title_map_idx[i] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_map_len = len(title_map)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for key,value in data_dict.items():\n",
    "    for question in data_dict[key]:\n",
    "        seq = [ word_to_index[word] for word in question.split() if word in word_to_index]\n",
    "        in_seq = pad_sequences([seq], maxlen=100, value=0, padding='post')[0]\n",
    "        X.append(in_seq)\n",
    "        out_seq = to_categorical([title_map[key]], num_classes=title_map_len)[0]\n",
    "        Y.append(out_seq)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(911, 135)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ques = Input(shape=(100,))\n",
    "embed = Embedding(input_dim = vocab_size,output_dim=64,mask_zero = True)(input_ques)\n",
    "lstm1 = LSTM(128,return_sequences = True)(embed)\n",
    "lstm2 = LSTM(128,return_sequences = False)(lstm1)\n",
    "dense1 = Dense(128,activation='relu')(lstm2)\n",
    "output = Dense(title_map_len,activation='softmax')(dense1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=input_ques,outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 100, 64)           108288    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 100, 128)          98816     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 135)               17415     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 372,615\n",
      "Trainable params: 372,615\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "29/29 [==============================] - 37s 206ms/step - loss: 4.8546 - accuracy: 0.0252\n",
      "Epoch 2/50\n",
      "29/29 [==============================] - 4s 155ms/step - loss: 4.6266 - accuracy: 0.0351\n",
      "Epoch 3/50\n",
      "29/29 [==============================] - 4s 139ms/step - loss: 4.2901 - accuracy: 0.0538\n",
      "Epoch 4/50\n",
      "29/29 [==============================] - 4s 140ms/step - loss: 3.9253 - accuracy: 0.0790\n",
      "Epoch 5/50\n",
      "29/29 [==============================] - 4s 139ms/step - loss: 3.5756 - accuracy: 0.1153\n",
      "Epoch 6/50\n",
      "29/29 [==============================] - 4s 136ms/step - loss: 3.1899 - accuracy: 0.1778\n",
      "Epoch 7/50\n",
      "29/29 [==============================] - 4s 135ms/step - loss: 2.9159 - accuracy: 0.2228\n",
      "Epoch 8/50\n",
      "29/29 [==============================] - 4s 146ms/step - loss: 2.6280 - accuracy: 0.2909\n",
      "Epoch 9/50\n",
      "29/29 [==============================] - 4s 135ms/step - loss: 2.3750 - accuracy: 0.3282\n",
      "Epoch 10/50\n",
      "29/29 [==============================] - 4s 134ms/step - loss: 2.2118 - accuracy: 0.3688\n",
      "Epoch 11/50\n",
      "29/29 [==============================] - 4s 135ms/step - loss: 2.0480 - accuracy: 0.4040\n",
      "Epoch 12/50\n",
      "29/29 [==============================] - 4s 137ms/step - loss: 1.9615 - accuracy: 0.4204\n",
      "Epoch 13/50\n",
      "29/29 [==============================] - 4s 137ms/step - loss: 1.7304 - accuracy: 0.4984\n",
      "Epoch 14/50\n",
      "29/29 [==============================] - 4s 135ms/step - loss: 1.5557 - accuracy: 0.5412\n",
      "Epoch 15/50\n",
      "29/29 [==============================] - 4s 136ms/step - loss: 1.3876 - accuracy: 0.6092\n",
      "Epoch 16/50\n",
      "29/29 [==============================] - 4s 137ms/step - loss: 1.2370 - accuracy: 0.6411\n",
      "Epoch 17/50\n",
      "29/29 [==============================] - 4s 137ms/step - loss: 1.2545 - accuracy: 0.6136\n",
      "Epoch 18/50\n",
      "29/29 [==============================] - 4s 135ms/step - loss: 1.1580 - accuracy: 0.6443\n",
      "Epoch 19/50\n",
      "29/29 [==============================] - 4s 135ms/step - loss: 1.0032 - accuracy: 0.7113\n",
      "Epoch 20/50\n",
      "29/29 [==============================] - 4s 136ms/step - loss: 0.8792 - accuracy: 0.7486\n",
      "Epoch 21/50\n",
      "29/29 [==============================] - 4s 136ms/step - loss: 0.7684 - accuracy: 0.7761\n",
      "Epoch 22/50\n",
      "29/29 [==============================] - 4s 136ms/step - loss: 0.7799 - accuracy: 0.7859\n",
      "Epoch 23/50\n",
      "29/29 [==============================] - 4s 137ms/step - loss: 0.6934 - accuracy: 0.7958\n",
      "Epoch 24/50\n",
      "29/29 [==============================] - 4s 135ms/step - loss: 0.5779 - accuracy: 0.8364\n",
      "Epoch 25/50\n",
      "29/29 [==============================] - 4s 137ms/step - loss: 0.5151 - accuracy: 0.8683\n",
      "Epoch 26/50\n",
      "29/29 [==============================] - 4s 135ms/step - loss: 0.5092 - accuracy: 0.8595\n",
      "Epoch 27/50\n",
      "29/29 [==============================] - 4s 137ms/step - loss: 0.4160 - accuracy: 0.8913\n",
      "Epoch 28/50\n",
      "29/29 [==============================] - 4s 136ms/step - loss: 0.3943 - accuracy: 0.8869\n",
      "Epoch 29/50\n",
      "29/29 [==============================] - 4s 136ms/step - loss: 0.3026 - accuracy: 0.9352\n",
      "Epoch 30/50\n",
      "29/29 [==============================] - 4s 138ms/step - loss: 0.2558 - accuracy: 0.9407\n",
      "Epoch 31/50\n",
      "29/29 [==============================] - 4s 136ms/step - loss: 0.2459 - accuracy: 0.9506\n",
      "Epoch 32/50\n",
      "29/29 [==============================] - 4s 135ms/step - loss: 0.2205 - accuracy: 0.9660\n",
      "Epoch 33/50\n",
      "29/29 [==============================] - 4s 138ms/step - loss: 0.1645 - accuracy: 0.9704\n",
      "Epoch 34/50\n",
      "29/29 [==============================] - 4s 138ms/step - loss: 0.1403 - accuracy: 0.9780\n",
      "Epoch 35/50\n",
      "29/29 [==============================] - 4s 136ms/step - loss: 0.1199 - accuracy: 0.9780\n",
      "Epoch 36/50\n",
      "29/29 [==============================] - 4s 135ms/step - loss: 0.0942 - accuracy: 0.9901\n",
      "Epoch 37/50\n",
      "29/29 [==============================] - 4s 136ms/step - loss: 0.0764 - accuracy: 0.9879\n",
      "Epoch 38/50\n",
      "29/29 [==============================] - 4s 136ms/step - loss: 0.0627 - accuracy: 0.9912\n",
      "Epoch 39/50\n",
      "29/29 [==============================] - 4s 140ms/step - loss: 0.0582 - accuracy: 0.9912\n",
      "Epoch 40/50\n",
      "29/29 [==============================] - 4s 136ms/step - loss: 0.0509 - accuracy: 0.9934\n",
      "Epoch 41/50\n",
      "29/29 [==============================] - 4s 137ms/step - loss: 0.0429 - accuracy: 0.9923\n",
      "Epoch 42/50\n",
      "29/29 [==============================] - 4s 137ms/step - loss: 0.0409 - accuracy: 0.9934\n",
      "Epoch 43/50\n",
      "29/29 [==============================] - 4s 138ms/step - loss: 0.0356 - accuracy: 0.9945\n",
      "Epoch 44/50\n",
      "29/29 [==============================] - 4s 141ms/step - loss: 0.0342 - accuracy: 0.9934\n",
      "Epoch 45/50\n",
      "29/29 [==============================] - 4s 140ms/step - loss: 0.0367 - accuracy: 0.9934\n",
      "Epoch 46/50\n",
      "29/29 [==============================] - 4s 137ms/step - loss: 0.0269 - accuracy: 0.9956\n",
      "Epoch 47/50\n",
      "29/29 [==============================] - 4s 138ms/step - loss: 0.0304 - accuracy: 0.9945\n",
      "Epoch 48/50\n",
      "29/29 [==============================] - 4s 140ms/step - loss: 0.0283 - accuracy: 0.9923\n",
      "Epoch 49/50\n",
      "29/29 [==============================] - 4s 140ms/step - loss: 0.0250 - accuracy: 0.9923\n",
      "Epoch 50/50\n",
      "29/29 [==============================] - 4s 142ms/step - loss: 0.0248 - accuracy: 0.9945\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X,Y,epochs=50,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inp):\n",
    "    x = []\n",
    "    inp = clean_text(inp)\n",
    "    seq = [ word_to_index[word] for word in inp.split() if word in word_to_index]\n",
    "    print(seq)\n",
    "    in_seq = pad_sequences([seq], maxlen=100, value=0, padding='post')[0]\n",
    "    print(in_seq)\n",
    "    x.append(in_seq)\n",
    "    x = np.array(x)\n",
    "    ypred = model.predict(x)\n",
    "    ypred = ypred.argmax()\n",
    "    return title_map_idx[ypred-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 14, 1, 919, 4, 8, 920, 6, 181, 7, 107, 451]\n",
      "[  3  14   1 919   4   8 920   6 181   7 107 451   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n",
      "ADOPTION UNDER CHRISTIAN LAW\n",
      "[131, 189, 9, 68]\n",
      "[131 189   9  68   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n",
      "DOWRY DEATH\n"
     ]
    }
   ],
   "source": [
    "print(predict( \"What are the points to be considerd for adoption in christian faith?\"))\n",
    "print(predict( \"Anything about sex and rape?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('checkpoint.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('checkpoint.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[282  31   1  54  43   6  12 115 283 570   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 14]\n",
      "[17 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'MAHILA COURTS'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"How are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ACID ATTACKS'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"anything else\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\abhay\\AppData\\Local\\Temp\\tmpul99azf1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\abhay\\AppData\\Local\\Temp\\tmpul99azf1\\assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2436604"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# These imports are required to load operators' definition.\n",
    "import tensorflow_text as tf_text\n",
    "import sentencepiece as spm\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.target_spec.supported_ops = [\n",
    "  tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS\n",
    "]\n",
    "model_data = converter.convert()\n",
    "open('model2.tflite','wb').write(model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow import lite\n",
    "# converter =lite.TFLiteConverter.from_keras_model(model)\n",
    "# converter.experimental_new_converter=True\n",
    "# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "# tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "\n",
    "# tfmodel = converter.convert()\n",
    "# open('converted_checkpoint_model.tflite','wb').write(tfmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python import keras\n",
    "# import tensorflow\n",
    "\n",
    "# modelnew = keras.models.load_model('checkpoint.h5')\n",
    "# converter=tensorflow.lite.TFLiteConverter.from_keras_model(modelnew)\n",
    "# tflite_model = converter.convert()\n",
    "# open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
